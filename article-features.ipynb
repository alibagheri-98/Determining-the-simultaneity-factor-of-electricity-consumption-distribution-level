{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import silhouette_score , davies_bouldin_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.metrics import roc_curve , auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve , roc_auc_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('trainlabels.npy',allow_pickle=True)\n",
    "labels_TEST = np.load('testlabels.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_array_list = np.load('traindata.npy',allow_pickle=True)\n",
    "s_cleaned_array_list_TEST = np.load('testdata.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_tot = list(s_cleaned_array_list)\n",
    "\n",
    "s_cleaned_tot.extend(list(s_cleaned_array_list_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_cleaned_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s = 0\n",
    "\n",
    "tr = 2\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    x = s_cleaned_array_list[i]\n",
    "    \n",
    "    dl_list_day = []\n",
    "    \n",
    "    e = s_cleaned_array_list[i][:,:24:2]\n",
    "    \n",
    "    for j in range(e.shape[0]):\n",
    "        \n",
    "        if np.sum(e[j]) <= tr :\n",
    "            \n",
    "            c_s += 1\n",
    "            \n",
    "            dl_list_day.append(j)\n",
    "            \n",
    "    x = np.delete(x,dl_list_day,axis=0)\n",
    "    \n",
    "    s_cleaned_array_list[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s = 0\n",
    "\n",
    "tr = 2\n",
    "\n",
    "for i in range(len(s_cleaned_array_list_TEST)):\n",
    "    \n",
    "    x = s_cleaned_array_list_TEST[i]\n",
    "    \n",
    "    dl_list_day = []\n",
    "    \n",
    "    e = s_cleaned_array_list_TEST[i][:,:24:2]\n",
    "    \n",
    "    for j in range(e.shape[0]):\n",
    "        \n",
    "        if np.sum(e[j]) <= tr :\n",
    "            \n",
    "            c_s += 1\n",
    "            \n",
    "            dl_list_day.append(j)\n",
    "            \n",
    "    x = np.delete(x,dl_list_day,axis=0)\n",
    "    \n",
    "    s_cleaned_array_list_TEST[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s_cleaned_array_list_TEST)):\n",
    "    \n",
    "    print(len(s_cleaned_array_list_TEST[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = []\n",
    "powers = []\n",
    "\n",
    "for i in range(len(s_cleaned_tot)):\n",
    "\n",
    "    e = s_cleaned_tot[i][:,:24:2].reshape(-1)\n",
    "    p = s_cleaned_tot[i][:,1::2].reshape(-1)\n",
    "    \n",
    "    for j in range(e.shape[0]):\n",
    "        \n",
    "        energies.append(e[j])\n",
    "        powers.append(p[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_med = np.percentile(powers,50)\n",
    "energy_med = np.percentile(energies,50)\n",
    "\n",
    "energy_q1 = np.percentile(energies,25)\n",
    "power_q1 = np.percentile(powers,25)\n",
    "\n",
    "energy_q3 = np.percentile(energies,75)\n",
    "power_q3 = np.percentile(powers,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s_e = []\n",
    "\n",
    "mean_s_p = []\n",
    "\n",
    "std_s_e = []\n",
    "\n",
    "std_s_p = []\n",
    "\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "      \n",
    "    e_s = s_cleaned_array_list[i][:,:24:2]\n",
    "    p_s = s_cleaned_array_list[i][:,1:24:2]\n",
    "    \n",
    "    a = np.mean(e_s)\n",
    "    c = np.mean(p_s)\n",
    "       \n",
    "    mean_s_e.append(np.sqrt(a))\n",
    "    mean_s_p.append(np.sqrt(c))\n",
    "    \n",
    "    a = np.std(e_s)\n",
    "    c = np.std(p_s)\n",
    "    \n",
    "    std_s_e.append(np.sqrt(a))\n",
    "    std_s_p.append(np.sqrt(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_e_ratio = []\n",
    "q1_p_ratio = []\n",
    "\n",
    "q2_e_ratio = []\n",
    "q2_p_ratio = []\n",
    "\n",
    "q3_e_ratio = []\n",
    "q3_p_ratio = []\n",
    "\n",
    "C_max_e = []\n",
    "C_max_p = []\n",
    "\n",
    "C_min_e = []\n",
    "C_min_p = []\n",
    "\n",
    "R_e_meanmax = []\n",
    "R_p_meanmax = []\n",
    "\n",
    "R_e_minmean = []\n",
    "R_p_minmean = []\n",
    "\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    \n",
    "    c3 = 0\n",
    "    c4 = 0\n",
    "    \n",
    "    c5 = 0\n",
    "    c6 = 0\n",
    "    \n",
    "    e = s_cleaned_array_list[i][:,:24:2].reshape(-1)\n",
    "    p = s_cleaned_array_list[i][:,1::2].reshape(-1)\n",
    "    \n",
    "    n = e.shape[0]\n",
    "    \n",
    "    for j in range(n):\n",
    "        \n",
    "        if e[j] >= energy_med:\n",
    "            \n",
    "            c1 += 1\n",
    "        \n",
    "        if p[j] >= power_med:\n",
    "            \n",
    "            c2 += 1\n",
    "\n",
    "        if e[j] >= energy_q1:\n",
    "            \n",
    "            c3 += 1\n",
    "        \n",
    "        if p[j] >= power_q1:\n",
    "            \n",
    "            c4 += 1\n",
    "\n",
    "        if e[j] >= energy_q3:\n",
    "            \n",
    "            c5 += 1\n",
    "        \n",
    "        if p[j] >= power_q3:\n",
    "            \n",
    "            c6 += 1\n",
    "            \n",
    "    q2_e_ratio.append(c1/n)\n",
    "    q2_p_ratio.append(c2/n)\n",
    "\n",
    "    q1_e_ratio.append(c3/n)\n",
    "    q1_p_ratio.append(c4/n)\n",
    "    \n",
    "    q3_e_ratio.append(c5/n)\n",
    "    q3_p_ratio.append(c6/n)\n",
    "    \n",
    "    C_max_e.append(np.max(e))\n",
    "    C_max_p.append(np.max(p))\n",
    "\n",
    "    C_min_e.append(np.log(np.min(e)+0.000001))\n",
    "    C_min_p.append(np.log(np.min(p)+0.000001))\n",
    "    \n",
    "    if np.min(p) == 0 :\n",
    "        \n",
    "        print(i)\n",
    "    \n",
    "    R_e_meanmax.append(np.log(np.mean(e)/np.max(e)))\n",
    "    R_p_meanmax.append(np.log(np.mean(p)/np.max(p)))\n",
    "\n",
    "    R_e_minmean.append(np.sqrt(np.sqrt(np.min(e)/np.mean(e))))\n",
    "    R_p_minmean.append(np.sqrt(np.sqrt(np.min(p)/np.mean(p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(np.vstack((q1_e_ratio,q1_p_ratio,q2_e_ratio,q2_p_ratio,q3_e_ratio,q3_p_ratio,\n",
    "                            C_max_e,C_max_p,C_min_e,C_min_p,R_e_meanmax,R_p_meanmax,R_e_minmean,R_p_minmean\n",
    "                            ,mean_s_e,mean_s_p,std_s_e,std_s_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_e = []\n",
    "\n",
    "means_p = []\n",
    "\n",
    "stds_e = []\n",
    "\n",
    "stds_p = []\n",
    "\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "      \n",
    "    e_s = s_cleaned_array_list[i][:,:24:2]\n",
    "    p_s = s_cleaned_array_list[i][:,1:24:2]\n",
    "    \n",
    "       \n",
    "    means_e.append(np.sqrt(np.mean(e_s,axis=0)))\n",
    "    means_p.append(np.sqrt(np.mean(p_s,axis=0)))\n",
    "    \n",
    "    stds_e.append(np.sqrt(np.std(e_s,axis=0)))\n",
    "    stds_p.append(np.sqrt(np.std(p_s,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X,means_e,means_p,stds_e,stds_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s_e = []\n",
    "\n",
    "mean_s_p = []\n",
    "\n",
    "std_s_e = []\n",
    "\n",
    "std_s_p = []\n",
    "\n",
    "\n",
    "for i in range(len(s_cleaned_array_list_TEST)):\n",
    "      \n",
    "    e_s = s_cleaned_array_list_TEST[i][:,:24:2]\n",
    "    p_s = s_cleaned_array_list_TEST[i][:,1:24:2]\n",
    "    \n",
    "    a = np.mean(e_s)\n",
    "    c = np.mean(p_s)\n",
    "       \n",
    "    mean_s_e.append(a)\n",
    "    mean_s_p.append(c)\n",
    "    \n",
    "    a = np.std(e_s)\n",
    "    c = np.std(p_s)\n",
    "    \n",
    "    std_s_e.append(a)\n",
    "    std_s_p.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_e_ratio = []\n",
    "q1_p_ratio = []\n",
    "\n",
    "q2_e_ratio = []\n",
    "q2_p_ratio = []\n",
    "\n",
    "q3_e_ratio = []\n",
    "q3_p_ratio = []\n",
    "\n",
    "C_max_e = []\n",
    "C_max_p = []\n",
    "\n",
    "C_min_e = []\n",
    "C_min_p = []\n",
    "\n",
    "R_e_meanmax = []\n",
    "R_p_meanmax = []\n",
    "\n",
    "R_e_minmean = []\n",
    "R_p_minmean = []\n",
    "\n",
    "\n",
    "for i in range(len(s_cleaned_array_list_TEST)):\n",
    "    \n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    \n",
    "    c3 = 0\n",
    "    c4 = 0\n",
    "    \n",
    "    c5 = 0\n",
    "    c6 = 0\n",
    "    \n",
    "    e = s_cleaned_array_list_TEST[i][:,:24:2].reshape(-1)\n",
    "    p = s_cleaned_array_list_TEST[i][:,1::2].reshape(-1)\n",
    "    \n",
    "    n = e.shape[0]\n",
    "    \n",
    "    for j in range(n):\n",
    "        \n",
    "        if e[j] >= energy_med:\n",
    "            \n",
    "            c1 += 1\n",
    "        \n",
    "        if p[j] >= power_med:\n",
    "            \n",
    "            c2 += 1\n",
    "\n",
    "        if e[j] >= energy_q1:\n",
    "            \n",
    "            c3 += 1\n",
    "        \n",
    "        if p[j] >= power_q1:\n",
    "            \n",
    "            c4 += 1\n",
    "\n",
    "        if e[j] >= energy_q3:\n",
    "            \n",
    "            c5 += 1\n",
    "        \n",
    "        if p[j] >= power_q3:\n",
    "            \n",
    "            c6 += 1\n",
    "            \n",
    "    q2_e_ratio.append(c1/n)\n",
    "    q2_p_ratio.append(c2/n)\n",
    "\n",
    "    q1_e_ratio.append(c3/n)\n",
    "    q1_p_ratio.append(c4/n)\n",
    "    \n",
    "    q3_e_ratio.append(c5/n)\n",
    "    q3_p_ratio.append(c6/n)\n",
    "    \n",
    "    C_max_e.append(np.max(e))\n",
    "    C_max_p.append(np.max(p))\n",
    "\n",
    "    C_min_e.append(np.log(np.min(e)+0.000001))\n",
    "    C_min_p.append(np.log(np.min(p)+0.000001))\n",
    "    \n",
    "    R_e_meanmax.append(np.log(np.mean(e)/np.max(e)))\n",
    "    R_p_meanmax.append(np.log(np.mean(p)/np.max(p)))\n",
    "\n",
    "    R_e_minmean.append(np.sqrt(np.sqrt(np.min(e)/np.mean(e))))\n",
    "    R_p_minmean.append(np.sqrt(np.sqrt(np.min(p)/np.mean(p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.transpose(np.vstack((q1_e_ratio,q1_p_ratio,q2_e_ratio,q2_p_ratio,q3_e_ratio,q3_p_ratio,\n",
    "                            C_max_e,C_max_p,C_min_e,C_min_p,R_e_meanmax,R_p_meanmax,R_e_minmean,R_p_minmean\n",
    "                            ,mean_s_e,mean_s_p,std_s_e,std_s_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_e = []\n",
    "\n",
    "means_p = []\n",
    "\n",
    "stds_e = []\n",
    "\n",
    "stds_p = []\n",
    "\n",
    "\n",
    "for i in range(len(s_cleaned_array_list_TEST)):\n",
    "      \n",
    "    e_s = s_cleaned_array_list_TEST[i][:,:24:2]\n",
    "    p_s = s_cleaned_array_list_TEST[i][:,1:24:2]\n",
    "    \n",
    "       \n",
    "    means_e.append(np.sqrt(np.mean(e_s,axis=0)))\n",
    "    means_p.append(np.sqrt(np.mean(p_s,axis=0)))\n",
    "    \n",
    "    stds_e.append(np.sqrt(np.std(e_s,axis=0)))\n",
    "    stds_p.append(np.sqrt(np.std(p_s,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.hstack((x_test,means_e,means_p,stds_e,stds_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labels\n",
    "y_test = labels_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = [0.001 , 0.01 , 0.1 , 1 , 10 , 100 , 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in c_list:\n",
    "\n",
    "    RF_clf =  SVC(C =i  , class_weight = 'balanced', tol = 1e-6 , probability = True  )\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 8)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in c_list:\n",
    "\n",
    "    RF_clf =  SVC(C =i, tol = 1e-6 , probability = True  )\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 8)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_train = X[:11]\n",
    "X_tr_test = X_test[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.vstack((X_tr_train,x_test[11:]))\n",
    "\n",
    "x_train = np.vstack((X_tr_test,x_train[11:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in c_list:\n",
    "\n",
    "    RF_clf =  SVC(C =i  , class_weight = 'balanced', tol = 1e-6 , probability = True  )\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 8)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in c_list:\n",
    "\n",
    "    RF_clf =  SVC(C =i, tol = 1e-6 , probability = True  )\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 8)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =time.perf_counter()\n",
    "\n",
    "GSVM_clf = SVC(C = 10, tol = 1e-6 , probability = True)\n",
    "GSVM_clf.fit(x_train,y_train)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "t_LR = t2-t1\n",
    "\n",
    "print(t_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=GSVM_clf.predict(x_test)\n",
    "\n",
    "ts_GSVM = GSVM_clf.score(x_test,y_test)\n",
    "tr_GSVM = GSVM_clf.score(x_train,y_train)\n",
    "\n",
    "print(\"%s: test Accuracy = %.4f%% - train Accuracy = %.4f%%\" % (\"Gaussian SVM\", ts_GSVM, tr_GSVM ))\n",
    "\n",
    "cm_GSVM=confusion_matrix(y_test,y_pred)\n",
    "print(cm_GSVM)\n",
    "print(classification_report(y_test,y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = GSVM_clf.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =time.perf_counter()\n",
    "\n",
    "GSVM_clf = SVC(C = 10 , class_weight = 'balanced', tol = 1e-6 , probability = True)\n",
    "GSVM_clf.fit(x_train,y_train)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "t_LR = t2-t1\n",
    "\n",
    "print(t_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=GSVM_clf.predict(x_test)\n",
    "\n",
    "ts_GSVM = GSVM_clf.score(x_test,y_test)\n",
    "tr_GSVM = GSVM_clf.score(x_train,y_train)\n",
    "\n",
    "print(\"%s: test Accuracy = %.4f%% - train Accuracy = %.4f%%\" % (\"Gaussian SVM\", ts_GSVM, tr_GSVM ))\n",
    "\n",
    "cm_GSVM=confusion_matrix(y_test,y_pred)\n",
    "print(cm_GSVM)\n",
    "print(classification_report(y_test,y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = GSVM_clf.predict_proba(x_test)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1,51):\n",
    "\n",
    "    RF_clf = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 51)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =time.perf_counter()\n",
    "\n",
    "GNB_clf = GaussianNB()\n",
    "GNB_clf.fit(x_train,y_train)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "t_LR = t2-t1\n",
    "\n",
    "print(t_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=GNB_clf.predict(x_test)\n",
    "\n",
    "ts_GNB = GNB_clf.score(x_test,y_test)\n",
    "tr_GNB = GNB_clf.score(x_train,y_train)\n",
    "\n",
    "print(\"%s: test Accuracy = %.4f%% - train Accuracy = %.4f%%\" % (\"naive bayes\", ts_GNB, tr_GNB ))\n",
    "\n",
    "cm_GNB=confusion_matrix(y_test,y_pred)\n",
    "print(cm_GNB)\n",
    "print(classification_report(y_test,y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1,11):\n",
    "\n",
    "    RF_clf = RandomForestClassifier(class_weight='balanced',max_depth = i)\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(100):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values[:10], train_scores[:10], '-o', label='Train')\n",
    "plt.plot(values[:10], test_scores[:10], '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(labels_gas)\n",
    "\n",
    "labels.extend(list(labels_water))\n",
    "\n",
    "labels.extend(list(labels_centeral))\n",
    "\n",
    "labels.extend(list(labels_nil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_array_list_nil = np.load('niloofar_array_list.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_array_list = list(s_cleaned_array_list_gas)\n",
    "\n",
    "s_cleaned_array_list.extend(list(s_cleaned_array_list_water))\n",
    "\n",
    "s_cleaned_array_list.extend(list(s_cleaned_array_list_centeral))\n",
    "\n",
    "s_cleaned_array_list.extend(list(s_cleaned_array_list_nil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_cleaned_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s = 0\n",
    "\n",
    "tr = 2\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    x = s_cleaned_array_list[i]\n",
    "    \n",
    "    dl_list_day = []\n",
    "    \n",
    "    e = s_cleaned_array_list[i][:,:24:2]\n",
    "    \n",
    "    for j in range(e.shape[0]):\n",
    "        \n",
    "        if np.sum(e[j]) <= tr :\n",
    "            \n",
    "            c_s += 1\n",
    "            \n",
    "            dl_list_day.append(j)\n",
    "            \n",
    "    x = np.delete(x,dl_list_day,axis=0)\n",
    "    \n",
    "    s_cleaned_array_list[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_list = []\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    if len(s_cleaned_array_list[i]) <= 7:\n",
    "        \n",
    "        dl_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_array_list = np.delete(s_cleaned_array_list,dl_list,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.delete(labels,dl_list,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels),len(s_cleaned_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2c = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    \n",
    "    if labels[i] != 2:\n",
    "            \n",
    "        labels_2c.append(0)\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        labels_2c.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s_e = []\n",
    "\n",
    "mean_s_p = []\n",
    "\n",
    "mean_a_e = []\n",
    "\n",
    "mean_a_p = []\n",
    "\n",
    "std_s_e = []\n",
    "\n",
    "std_s_p = []\n",
    "\n",
    "std_a_e = []\n",
    "\n",
    "std_a_p = []\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "      \n",
    "    e_s = s_cleaned_array_list[i][:,:24:2]\n",
    "    p_s = s_cleaned_array_list[i][:,1:24:2]\n",
    "\n",
    "        \n",
    "    \n",
    "    a = np.mean(e_s)\n",
    "    c = np.mean(p_s)\n",
    "       \n",
    "    mean_s_e.append(a)\n",
    "    mean_s_p.append(c)\n",
    "\n",
    "    \n",
    "    a = np.std(e_s)\n",
    "    c = np.std(p_s)\n",
    "\n",
    "    std_s_e.append(a)\n",
    "    std_s_p.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_old = np.transpose(np.vstack((mean_s_e,mean_s_p,std_s_e,std_s_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_old\n",
    "y = labels_2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 57 , random_state=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1,351):\n",
    "\n",
    "    RF_clf =  SVC(C =i  , class_weight = 'balanced', tol = 1e-6 , probability = True )\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 351)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(values[100:150], train_scores[100:150], '-o', label='Train')\n",
    "plt.plot(values[100:150], test_scores[100:150], '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = (np.vstack((X[:i],X[i+1:])) , X[i,:] , np.vstack((np.array(y[:i]).reshape((-1,1)),np.array(y[i+1:]).reshape((-1,1)))), y[i] )\n",
    "    \n",
    "    \n",
    "    RF_clf =  SVC(C = 2  , class_weight = 'balanced', tol = 1e-6 , probability = True )\n",
    "\n",
    "\n",
    "    RF_clf.fit(x_train,y_train)\n",
    "\n",
    "    y_pred=RF_clf.predict(x_test.reshape(1, -1))\n",
    "    \n",
    "    prob = RF_clf.predict_proba(x_test.reshape(1, -1))[0]\n",
    "    \n",
    "    if y_test != y_pred[0]:\n",
    "        \n",
    "        print(i,y_test,prob[0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = (np.vstack((X[:i],X[i+1:])) , X[i,:] , np.vstack((np.array(y[:i]).reshape((-1,1)),np.array(y[i+1:]).reshape((-1,1)))), y[i] )\n",
    "    \n",
    "    \n",
    "    RF_clf =  SVC(C = 120  , class_weight = 'balanced', tol = 1e-6 , probability = True )\n",
    "\n",
    "\n",
    "    RF_clf.fit(x_train,y_train)\n",
    "\n",
    "    y_pred=RF_clf.predict(x_test.reshape(1, -1))\n",
    "    \n",
    "    prob = RF_clf.predict_proba(x_test.reshape(1, -1))[0]\n",
    "    \n",
    "    if y_test != y_pred[0]:\n",
    "        \n",
    "        print(i,y_test,prob,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s_cleaned_array_list)):\n",
    "\n",
    "    \n",
    "    f = plt.figure(figsize=(15,5))\n",
    "    ax = f.add_subplot(121)\n",
    "    ax2 = f.add_subplot(122)\n",
    "    plt.title(str(i))\n",
    "    ax.plot(s_cleaned_array_list[i][:,:24:2].reshape(-1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_list_ml = [99,165,180,181,182,265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_array_list = np.delete(s_cleaned_array_list,dl_list_ml,axis = 0)\n",
    "\n",
    "labels = np.delete(labels,dl_list_ml,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_cleaned_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2c = np.delete(labels_2c,dl_list_ml,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = np.load('testdata_before_ml.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_l = []\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    for j in range(len(test_s)):\n",
    "        \n",
    "        if np.array_equal(test_s[j],s_cleaned_array_list[i]):\n",
    "            \n",
    "            dl_l.append(i)\n",
    "            \n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dl_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cleaned_array_list = np.delete(s_cleaned_array_list,dl_l,axis = 0)\n",
    "\n",
    "labels = np.delete(labels,dl_l,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_cleaned_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2c = np.delete(labels_2c,dl_l,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('traindata.npy',s_cleaned_array_list)\n",
    "np.save('trainlabels.npy',labels_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s[j] == s_cleaned_array_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s[-1] in s_cleaned_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isinf(test_s[-1],s_cleaned_array_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_s[-1] == test_s[-1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s_e = []\n",
    "\n",
    "mean_s_p = []\n",
    "\n",
    "mean_a_e = []\n",
    "\n",
    "mean_a_p = []\n",
    "\n",
    "std_s_e = []\n",
    "\n",
    "std_s_p = []\n",
    "\n",
    "std_a_e = []\n",
    "\n",
    "std_a_p = []\n",
    "\n",
    "for i in range(len(s_cleaned_array_list)):\n",
    "      \n",
    "    e_s = s_cleaned_array_list[i][:,:24:2]\n",
    "    p_s = s_cleaned_array_list[i][:,1:24:2]\n",
    "    \n",
    "    e_a = a_cleaned_array_list[i][:,:24:2]\n",
    "    p_a = a_cleaned_array_list[i][:,1:24:2]\n",
    "        \n",
    "    \n",
    "    a = np.mean(e_s)\n",
    "    b = np.mean(e_a)\n",
    "    c = np.mean(p_s)\n",
    "    d = np.mean(p_a)\n",
    "       \n",
    "    mean_s_e.append(a)\n",
    "    mean_s_p.append(c)\n",
    "    mean_a_e.append(b)\n",
    "    mean_a_p.append(d)\n",
    "    \n",
    "    a = np.std(e_s)\n",
    "    b = np.std(e_a)\n",
    "    c = np.std(p_s)\n",
    "    d = np.std(p_a)\n",
    "\n",
    "    \n",
    "    std_s_e.append(a)\n",
    "    std_s_p.append(c)\n",
    "    std_a_e.append(b)\n",
    "    std_a_p.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_old = np.transpose(np.vstack((ett_slopes,ptt_slopes,mean_s_e,mean_s_p,mean_a_e,mean_a_p,std_s_e,std_s_p,std_a_e,std_a_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_old\n",
    "y = labels_2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s_cleaned_array_list)):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = (np.vstack((X[:i],X[i+1:])) , X[i,:] , np.vstack((np.array(y[:i]).reshape((-1,1)),np.array(y[i+1:]).reshape((-1,1)))), y[i] )\n",
    "    \n",
    "    \n",
    "    RF_clf =  SVC(C = 2  , class_weight = 'balanced', tol = 1e-6 , probability = True )\n",
    "\n",
    "\n",
    "    RF_clf.fit(x_train,y_train)\n",
    "\n",
    "    y_pred=RF_clf.predict(x_test.reshape(1, -1))\n",
    "    \n",
    "    prob = RF_clf.predict_proba(x_test.reshape(1, -1))[0]\n",
    "    \n",
    "    if y_test != y_pred[0]:\n",
    "        \n",
    "        print(i,y_test,prob,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s_cleaned_array_list)):\n",
    "\n",
    "    \n",
    "    f = plt.figure(figsize=(15,5))\n",
    "    ax = f.add_subplot(121)\n",
    "    ax2 = f.add_subplot(122)\n",
    "    plt.title(str(i))\n",
    "    ax.plot(s_cleaned_array_list[i][:,:24:2].reshape(-1))\n",
    "    ax2.plot(a_cleaned_array_list[i][:,:24:2].reshape(-1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 0.25 , random_state=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1,200):\n",
    "\n",
    "    RF_clf =  SVC(C = i*0.01 + 0.01  , class_weight = 'balanced', tol = 1e-6 , probability = True )\n",
    "\n",
    "    test_list = []\n",
    "    train_list = []\n",
    "\n",
    "    for j in range(1):\n",
    "\n",
    "        RF_clf.fit(x_train,y_train)\n",
    "\n",
    "        y_pred=RF_clf.predict(x_test)\n",
    "\n",
    "        ts_RF = RF_clf.score(x_test,y_test)\n",
    "        tr_RF = RF_clf.score(x_train,y_train)\n",
    "\n",
    "        test_list.append(ts_RF)\n",
    "        train_list.append(tr_RF)\n",
    "\n",
    "    test_scores.append(np.mean(test_list))\n",
    "    train_scores.append(np.mean(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(1, 200)]\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(values, train_scores, '-o', label='Train')\n",
    "plt.plot(values, test_scores, '-o', label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 23)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_list = []\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 73)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 123)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 173)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 223)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 248)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 261)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 267)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size= 271)\n",
    "    \n",
    "    GSVM_clf = SVC(C =  1 , class_weight = 'balanced', tol = 1e-6 , probability = True , gamma = 'auto')\n",
    "    GSVM_clf.fit(x_train,y_train)\n",
    "    \n",
    "    yproba = GSVM_clf.predict_proba(x_test)[::,1]\n",
    "    auc_scores_list.append(roc_auc_score(y_test, yproba))\n",
    "    \n",
    "print(np.mean(auc_scores_list),np.std(auc_scores_list),np.max(auc_scores_list),np.min(auc_scores_list))\n",
    "\n",
    "bx_list.append(auc_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(bx_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
